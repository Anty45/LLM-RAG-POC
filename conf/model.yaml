# llm model
llm_type: "llamacpp"
llm_openai_model: "gpt-3.5-turbo"
llm_llama_model_url: "https://huggingface.co/TheBloke/Vigogne-2-7B-Chat-GGUF/resolve/main/vigogne-2-7b-chat.Q5_K_M.gguf"
llm_llama_path: ressources/llm_model/vigogne-2-7b-chat.Q5_K_M.gguf

# llm params
model_temperature : 0.5
max_new_tokens: 256
chunk_size: 256
low_cpu_mem_usage: 1
verbose: 1
n_gpu_layers: 4

# documents
node_chunk_size: 950

# embedding
embbeding: "dangvantuan/sentence-camembert-base"


# chat prompt
text_qa_template: 1
chat_mode: 'condense_question'


# Force indexing
force_indexing : 1

# evaluation
chunk_questions_to_generate : 2
doc_nb_for_eval: 1
