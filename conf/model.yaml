# llm model
llm_type: "llamacpp"
llm_openai_model: "gpt-3.5-turbo"
llm_llama_model_url: "https://huggingface.co/TheBloke/Vigogne-2-7B-Chat-GGUF/resolve/main/vigogne-2-7b-chat.Q5_K_M.gguf"
llm_llama_path: ressources/llm_model/vigogne-2-7b-chat.Q5_K_M.gguf

# llm params
model_temperature : 0.7
max_new_tokens: 1024
chunk_size: 256
low_cpu_mem_usage: 1
verbose: 1
n_gpu_layers: 4

# embedding
embbeding: "dangvantuan/sentence-camembert-base"

# index

# chat prompt
text_qa_template: 1
chat_mode: 'condense_question'


# Force indexing
force_indexing : 1
